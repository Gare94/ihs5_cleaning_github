---
title: "Outlier management and edible portions"
author: "Gareth Osman"
date: "7/18/2023"
output: html_document
---

>PACKAGES

```{r}
#--- Load libraries 
library(tidyverse)

options(digits=3)

```

>DATA 

```{r}
#--- Load most updated data

ihs5 <- read.csv(here::here('inter-output', 'hh_mod_g_kg.csv'))
ihs5 <- select(ihs5, -X)

hh.hme <- read.csv(here::here('inter-output', 'hme.final.csv'))
hh.hme <- select(hh.hme, -X)

```

>Manage outliers: eliminate by excess food item intake

Some individual food items may be overestimated due to stockpiling or purchases in bulk. Generally not a problem for surveys which have shorter recall periods but it doesn't hurt to check to see if there any unusual overestimates of particular food items. In this chunk, I divided the kgs of each food items consumed by the per capita (AME, as widely used in HCES analysis) and the total number of days in the recall to get the total kgs consumed per day.  

Consumption quantity generally tends to be non-normally distributed with a right skew, so to define a more approriate cut-off, we can just log-transform the distribution to normalize and then take +4SDs and +5SD from the mean to identify households with potential unreasonable consumption estimates. Because in normal distribution 99.73% of the data should be +/-3SD around the mean (Mean+/-3SD). For this analysis, it's slightly more complicated since there were a number of consumption quantities <1, meaning the log transformed value would be negative making calculating the SD a bit more challenging. To overcome this, for each consumption value I just applied the fuction f(x) = log(x)+1 to ensure that SDs (or in this case SD+1) could be calculated for all food items. 

After identifying the potential outliers, I scanned through the list to see what was the potential cause of the deviation from the mean and if the reason warranted exclusion/reassignment of the value. There seemed to be three general reasons for the increased reported consumption:
  1. households actually consumed that much more of the food item;
  2. households purchased items in bulk/stockpiled and recalled the entire quantity purchased rather than the entire quantity consumed;
  3. misreport by eneumerator (e.g. cons_quant reported as "250" for  "250g tin" when in reality it should just be "1 250g tin").
  
In general, it is pretty difficult to differentiate between whether the increased cons_quant is due to reason 1 or reason 2 listed above. Some food items/associated quantities are more obvious (e.g. 1kg of salt per person per day) but most are a toss up. I think that this issue is well recognized in HCES data overall, so I think it is best to replace all these identified outlier values as we risk over-cleaning the data. Therefore, for this exercise I decided to clean out values using a hard-line rule and replaced all outliers with the median value of that consumed quantity for the food item. 

```{r}

ihs5 <- merge(x=ihs5, y=hh.hme, by.x='HHID', by.y='HHID', fill=-9999, all.x = TRUE)

ihs5$kg_ame_d <- ihs5$kg_d/ihs5$ame

```
# plot a histogram with boxplot and QQ plot of data in x indicating
# any probable outliers by Tukey's criterion
```{r}

summaplot<-function(x,varname){
x <- na.omit(x)
if(missing(varname)){varname<-"x"}

Q1<-quantile(x,prob=0.25)
Q3<-quantile(x,prob=0.75)
Q2<-quantile(x,prob=0.5)
hspread<-Q3-Q1
Fu<-Q3+3*hspread
Fl<-Q1-3*hspread

ols<-which(x<Fl)
oll<-which(x>Fu)
posols<-which(x<(Q1-1.5*hspread))
if(length(posols)==0){
lw<-min(x)}else{
lw<-min(x[-posols])}
posoll<-which(x>(Q3+1.5*hspread))
if(length(posoll)==0){
uw<-max(x)}else{
uw<-max(x[-posoll])}

ol<-c(ols,oll) # combined outlier set
par(mfrow=c(1,2))
ymax<-max((hist(x,plot=F))$counts)
hist(x,main="",col="AliceBlue", xlab=varname,ylim=c(0,(ymax*1.25)))

boxmin<-ymax*1.1
boxmax<-ymax*1.2
boxmid<-ymax*1.15

lines(c(Q1,Q3),c(boxmin,boxmin))
lines(c(Q1,Q3),c(boxmax,boxmax))
lines(c(Q1,Q1),c(boxmin,boxmax))
lines(c(Q3,Q3),c(boxmin,boxmax))
lines(c(Q1,lw),c(boxmid,boxmid))
lines(c(Q3,uw),c(boxmid,boxmid))
lines(c(Q2,Q2),c(boxmin,boxmax),lwd=2)

lines(c(Fu,Fu),c(10,boxmid),lty=5,col="red")
lines(c(Fl,Fl),c(10,boxmid),lty=5,col="red")

qqn<-qqnorm(x,main="",pch=16)
qqline(x)
points(qqn$x[ol],qqn$y[ol],pch=16,col="red")

}
####################################################################
```

```{r}
#Consumption (kg/capita/day) (113= Biscuits, 803=cooking oil, 703= margarine, etc)

summaplot(ihs5[ihs5$item_code == 113, "kg_ame_d"])

ihs5 %>% filter(item_code==113) %>% ggplot(., aes(x=kg_ame_d)) + 
    geom_boxplot() +
    theme_bw()

ihs5 <- ihs5 %>% mutate(log.kg_ame_d.plus1 =log(kg_ame_d+1))

```

```{r}
#Calculating medians & SD 
ihs5.summ <- ihs5 %>% group_by(item_code) %>% 
    summarise(n=n(), 
          mean.logplus1=mean(log(kg_ame_d+1), na.rm = TRUE), 
          median=median(kg_ame_d, na.rm = TRUE), 
          sd.logplus1=sd(log(kg_ame_d+1), na.rm = TRUE))

ihs5.summ.merg <- ihs5.summ %>% mutate(sd4 = sd.logplus1*4) %>% mutate(sd5 = sd.logplus1*5) %>% select(item_code, mean.logplus1, median, sd4, sd5)

ihs5.summ.merg <- ihs5.summ.merg %>% mutate(cut4 = sd4 + mean.logplus1) %>% mutate(cut5 = sd5 + mean.logplus1) %>% select(item_code, median, cut4, cut5)

ihs5 <- ihs5 %>% left_join(., ihs5.summ.merg, by=("item_code")) %>% arrange(HHID)

ihs5 <- ihs5 %>% mutate(ol4 = cut4-log.kg_ame_d.plus1)
ihs5 <- ihs5 %>% mutate(outlier4 = ifelse(ol4<0, 1, NA)) 

ihs5 <- ihs5 %>% mutate(ol5 = cut5-log.kg_ame_d.plus1)
ihs5 <- ihs5 %>% mutate(outlier5 = ifelse(ol5<0, 1, NA)) 

 ihs5$outlier.id <- paste0(as.character(ihs5$HHID),"_", as.character(ihs5$item_code))

outliers <- ihs5 %>% filter(outlier5==1) %>% select(HHID, outlier5, item_code, item_name_original, unit_name, cons_quant, cons_unitA, kg_d, ame, kg_ame_d, outlier.id, median, cut5) %>% arrange(item_code)

outliers$sdkg5 <- 10^outliers$cut5-1
outliers$kg_d_replace <-outliers$median * outliers$ame

 write.csv(outliers, here::here('output', 'ihs5.outliers.5sd2.csv'))
 
 outliers.c <- outliers %>% select(outlier.id, kg_d_replace)
 
ihs5 <- merge(x=ihs5, y=outliers.c , by.x='outlier.id', by.y='outlier.id', fill=-9999, all.x = TRUE)

ihs5 <- ihs5 %>% mutate(kg_d2=ifelse(!is.na(kg_d_replace),kg_d_replace, kg_d))

```

>EDIBLE PORTIONS OF FOOD ITEMS

This step entails removing food weights that were recalled as part of the HCES questionnaire but were never consumed in the household due to processing, preparation, or cooking. This includes food remnants such as banana peels, groundnut shells, and skin from peeled tubers, as well as bones from large fish that were discarded etc. As a result, we'll need to import a file containing Caloric conversion factor data from the World Bank's data catalog (https://microdata.worldbank.org/index.php/catalog/3818), which included information about the edible portion of each food item. However, the data is incomplete, as twenty food items lack edible portion information. To resolve the issue, we imputed edible portion factors using West Africa FCT (WFCT) and Kenyan FCT (KENFCT) accordingly. We used a "analyst's best estimate" for the items that still lacked edible portion factors. Therefore, the 'edible_portion_clean' is the complete file of edible portions of food items. 

```{r}

EP <- read.csv (here::here('inter-output', 'edible_portion_clean.csv'))

EP<- EP %>% select(item_code, edible_p)

EP$item_code <- as.factor(EP$item_code)
ihs5$item_code <- as.factor(ihs5$item_code)

ihs5<- ihs5 %>% left_join(., EP, by= 'item_code')

ihs5$kg_d_nep <- ihs5$kg_d2 * (ihs5$edible_p/100)

ihs5$g100_d_nep <-ihs5$kg_d_nep*10

```

>DONE:  ARCHIVE

```{r}

ihs5 <- ihs5 %>% select(HHID, item_code, g100_d_nep)

write.csv(ihs5, here::here('inter-output', 'hh_mod_g_nep.csv'))

```
